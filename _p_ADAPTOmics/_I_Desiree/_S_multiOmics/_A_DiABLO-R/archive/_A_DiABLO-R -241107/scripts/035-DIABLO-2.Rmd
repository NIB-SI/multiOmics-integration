```{r echo=FALSE}
###############################################
##                                           ##
## (c) Andrej Blejec (andrej.blejec@nib.si)  ##
##                                           ##
###############################################
```
```{r echo=FALSE,results='hide'}
options(width=70)
```
Child: 035-DIABLO-2.Rmd
## DIABLO `r paste(names(CCDATA[-1]),sep=", ")`
## DIABLO

DIABLO from **`mixOmics`**  enables integration of more than two datasets.

## Organize data

Thre datasets are organized as a list of matrices with same samples as rows and variables in columns.

```{r }
data <- CCDATA[-1]
str(data)
length(data)
```


In addition, outcome, phenotypic state or in our case treatment can also be determined. We have combination of two treatments and four time points.

```{r }
state <- factor(CCDATA[[1]])
table(state)
str(state)

```

## Initial analysis

Note: Additional insights can be found at 
http://mixomics.org/mixdiablo/diablo-tcga-case-study/.

### Pairwise PLS comparisons

```{r }
list.keepX = c(25, 25) # select arbitrary values of features to keep
list.keepY = c(25, 25)
```


```{r  fig.cap="Circle Correlation Plots for pairwise PLS models on ADAPT data. At most top 25 features for each dimension with correlation above 0.5, are displayed.", fig.height=7}
par(mfrow=c(2,2))
pairs <- combn(1:length(names(data)),2)
nms <- names(data)
outn <- ""
j <- 1
ncomp <- length(data)

cols <- c('orange1', 'brown1', 'lightgreen','lightblue','pink')[1:length(data)]
pchs <- c(16, 17, 15, 18,20)[1:length(data)]
j <- 1
cutoff <- 0.5
for(j in 1:ncol(pairs) ){
    pair <- pairs[,j]
    pair
    X <- CCDATA[[pair[1]+1]]
    Y <- CCDATA[[pair[2]+1]]
    list.keepX <- rep(min(ncol(X), 25), ncomp)
    list.keepY <- rep(min(ncol(Y), 25), ncomp)
    x <- spls(X, Y, ncomp=ncomp, keepX = list.keepX, keepY = list.keepY)
    assign(paste0("spls",j),x)
    cat("\n",paste(nms[pair]), "\n")
    cat("Results in:",paste0("spls",j),"\n")
    cat("Correlation between pls variates:\n")
    print(round(cor(x$variates$X, x$variates$Y),5))
#
   plotVar(x, cutoff = cutoff, title = paste(nms[pair],collapse=", "),
        legend = c(nms[pair][1], nms[pair][2]),
        var.names = FALSE, style = 'graphics',
        pch = pchs[pair], cex = c(2,2),
        col = cols[pair])
}
```

### Initial DIABLO model

Following the suggestion in the source, we will use 
design matrices with small values. 
This is supposed to keep low classification error rate.

```{r }
entry <- .entry
design = matrix(entry, ncol = length(data), nrow = length(data),
                dimnames = list(names(data), names(data)))
diag(design) = 0 # set diagonal to 0s

design
```

With a design in place, the initial DIABLO model can be generated. An arbitrarily high number of components (ncomp = 5) will be used.
```{r }
# form basic DIABLO model
Y <- state
basic.diablo.model = block.splsda(X = data, Y = Y, ncomp = 5, design = design)
```


```{r}
######################################## test eval
knitr::opts_chunk$set(eval=!FALSE)
```

### Tuning the number of components

Details of tuning process can be found in the 
http://mixomics.org/mixdiablo/diablo-tcga-case-study/.

The process can be computer time consuming and was performed separately. 

 From previous tuning sessions one can conclude, that the classification rate stays roughly unchanged after two to four components, so we will set the number of components to the number of data sets:


```{r }
ncomp <- length(data)
ncomp
```

### Tuning the number of features

We choose the optimal number of variables to select in each data set using the tune.block.splsda() function, for a grid of keepX values for each type of omics. Note that the function has been set to favour a relatively small signature while allowing us to obtain a sufficient number of variables for downstream validation and/or interpretation. See ?tune.block.splsda.


 Previous analyses suggest the following list:
 
   $metabolomics   
      [1] 10 10 5   
   $hormonomics   
      [1] 5 5 10   
   $qPCR   
      [1] 10 10 5 
        
Number of kept variates is limited with the minimal number of 
variates in the datasets. We have decided to keep at most 10 variates for each component.  
```{r }
min_variates <- min(sapply(data,ncol),10)
if(FALSE) keepX <- list(
    metabolomics = rep(10, ncomp),
    hormonomics = rep(10, ncomp),
    qPCR = rep(10, ncomp)
    )
list.keepX = list()
for (i in 1:length(data)) list.keepX[[i]] <- rep(min_variates, ncomp)
names(list.keepX) <- names(data)
list.keepX
```

## Final model

The final DIABLO model is run as:

```{r }
# set the optimised DIABLO model
final.diablo.model = block.splsda(X = data, Y = as.factor(state)
                          ,  ncomp = ncomp
                          , keepX = list.keepX
                          , design = design)

```

The selected variables can be extracted with the function selectVar(), for example in each block, as seen below. Note that the stability of selected variables can be extracted from the output of the perf() function.

```{r }
# the features selected from components
for (comp in 1:ncomp){
cat("\nComponent ", comp,":\n")
for(i in 1:length(data)){
cat(names(data)[i],"\n")
print(selectVar(final.diablo.model, comp = comp)[[i]]$name)
}
}
```

## Sample plots

plotDIABLO() is a diagnostic plot to check whether the correlation between components from each data set has been maximised as specified in the design matrix. We specify which dimension to be assessed with the ncomp argument.

```{r fig.height=7}
for(comp in 1:ncomp){
plotDiablo(final.diablo.model, ncomp = comp)
title(paste("Component",comp), adj=0.1, line=-1, outer=TRUE)
}
```

The sample plot with the plotIndiv() function projects each sample into the space spanned by the components of each block. Clustering of the samples can be  assessed with this plot.

```{r fig.height=7}
plind <- plotIndiv(final.diablo.model, 
          ind.names = FALSE, 
          legend = TRUE,
          title = 'DIABLO Sample Plots',
          guide="none",
          ellipse = TRUE
          )
```

In the arrow plot below, the start of the arrow indicates the centroid between all data sets for a given sample and the tips of the arrows indicate the location of that sample in each block. Such graphics highlight the agreement between all data sets at the sample level. While somewhat difficult to interpret, even qualitatively, this arrow plot shows proximities of C01 and H01 (both day 1), C07 and C08, and H07 and H08 ( both a day apart). While C samples are in forth quadrant ( D1 < 0, D2 > 0), H samples have ( D1 < 0, D2 < 0) except H14 that is separated on the positive part of Dimension 1.

```{r plotArrow, fig.height=7}
plotArrow(final.diablo.model, ind.names = FALSE, legend = TRUE,
          title = paste(groups,collapse=", ")

          )
```

## Variable plots

Several graphical outputs are available to visualise and mine the associations 
between the selected variables.

The best starting point to evaluate the correlation structure 
between variables is with the correlation circle plot. A majority of the qPCR variables are positively correlated only with the first component. The hormonomics and metabolomics variables seem to separate along first two dimensions. These first two components correlate highly with the selected variables from the all three dataset. From this, the correlation of each selected feature from all three datasets can be evaluated based on their proximity. 


```{r fig.width=8, fig.height=8}
#if(length(data)==3) pick <- 1:3 else pick <- c(4,1:3)
#cols <- c('orange1', 'brown1', 'lightgreen',"lightblue")[pick]
#pchs <- c(16, 17, 15, 18)[pick]
cols <- c('orange1', 'brown1', 'lightgreen','lightblue','pink')[1:length(data)]
pchs <- c(16, 17, 15, 18,20)[1:length(data)]
plotVar(final.diablo.model, var.names = FALSE,
        style = 'graphics', legend = TRUE
        , pch = pchs, cex = rep(2,length(data))
        , col = cols
)


```

The circos plot is exclusive to integrative frameworks and represents 
the correlations between variables of different types, represented on the side quadrants. It seems that the qPCR variables are almost entirely negatively correlated with the other two dataframes. Just few from metabolomics and hormonomics are positively correlated.  Note that these correlations are above a value of 0.7 (cutoff = 0.7). All  interpretations made above are only relevant for features with very strong correlations.

Plot variables

```{r fig.width=8,fig.height=c(7,13)[1+(length(data)>4)]}
#plotVar(res, cutoff=0.5, legend = TRUE, overlap=!FALSE, style='graphics')
#plotVar(res, cutoff=0.5, legend = TRUE, overlap=FALSE, style='graphics')
plotVar(final.diablo.model, cutoff=0.5, legend = FALSE, comp=c(1,2), overlap=FALSE, col=cols,cex=rep(4,length(data)))
plotVar(final.diablo.model, cutoff=0.5, legend = FALSE, comp=c(2,3), overlap=FALSE, col=cols,cex=rep(4,length(data)))
```

```{r fig.width=7, fig.height=7}
circosPlot(final.diablo.model, cutoff = 0.7, line = TRUE,
           color.blocks= cols,
           color.cor = c(3,2), size.labels = 1
           , xpd=TRUE)
```

## Relevance networks

Another visualisation of the correlations between the different types of
variables is the relevance network, which is also built on the similarity
matrix (as is the circos plot). Colour represent variable type.

```{r 035a, results='asis'}
blocks <- combn(length(data),2)
j <- 1
cutoff <- 0.8
out35a <- ""
for(j in 1:ncol(blocks)){
    out35a <- paste( out35a, knit_child("035a-DIABLO-network.Rmd", quiet=!TRUE))

        if(interactive()) readline()
}
cat(out35a)
```

## Multipartite network

```{r results='asis'}
cutoff <- 0.0
x <- final.diablo.model
layout.fun <- NULL
label <- paste(.treat, collapse=", ")
out35b <- ""
  out35b <- paste( out35b, knit_child("035b-multipartite-network.Rmd", quiet=TRUE))
cat(out35b)
```


```{r }
# Save network layout in ly, used by my.layout function.
if(exists(deparse(substitute(nw)))) ly <- nw$layout else ly <- NULL

```

```{r results='asis'}
cutoff <- 0.8
x <- final.diablo.model
label <- paste(.treat, collapse=", ")
out35b <- ""
  out35b <- paste( out35b, knit_child("035b-multipartite-network.Rmd", quiet=TRUE))
cat(out35b)
```

## Visualize loadings

The function "plotLoadings" visualises the loading weights of each selected  variable on each component and each data set. The colour indicates the class in which the variable has the maximum level of expression "contrib = 'max'" using the median "method = 'median'". Figure below depicts the loading values for each dimension.

```{r plotLoadings, fig.height=7}
for(i in 1:ncomp)
plotLoadings(final.diablo.model, comp = i, contrib = 'max', method = 'median')

```

## Clustered image map  ( Heatmap )

The cimDIABLO() function is a clustered image map specifically implemented 
to represent the multi-omics molecular signature expression for each sample. From figure below the areas of homogeneous expression levels for a set of samples across a set of features can be determined. For instance, the H14 samples were the only group to show extremely high levels of expression for a specific set of genes and metabolites. This indicates these features are fairly discriminating for this subtype.

```{r}
cimfn <- "../reports/figs/cim.png"
```

```{r cim1}
png(cimfn, res = 600, width = 4000, height = 4000)
cimDiablo(final.diablo.model, size.legend=0.7)
dev.off()

```

![`r cimfn`](`r cimfn`)

## AUC and ROC plots

An AUC plot per block can also be obtained using the function auroc(). 
The interpretation of this output may not be particularly insightful in relation to the performance evaluation of our methods, but can complement the statistical analysis.

```{r }
par(mfrow=c(2,2))
for(i in 1:length(data))
auc.splsda = auroc(final.diablo.model, roc.block = names(data[i]),
                   roc.comp = 1, print = FALSE)
```

Save finil DIABLO model for future use in networks.
```{r }
res <- final.diablo.model
```

Estimate classification error rate. The error rate should drop by more components used.

```{r }
# run component number tuning with repeated CV
system.time(perf.diablo  <-  perf(res, validation = 'Mfold',
                   folds = 3, nrepeat = 10))

plot(perf.diablo) # plot output of tuning

```

## Names of kept variables

```{r }
# the features selected to form components
for (comp in 1:ncomp){
cat("\nComponent ", comp,":\n")
for(i in 1:length(data)){
cat(names(data)[i],"\n")
print(selectVar(res, comp = comp)[[i]]$name)
}
}
```

One would like to reduce the number of nodes, especially for proteomics data. One option is to reduce datasets in a way to keep only the variables in the selectVars in original data in .
We will keep variables from the first two components.

```{r }
keptVars <- unique(c(
 selectVar(res, comp=1)[[1]]$name
,selectVar(res, comp=2)[[1]]$name
)
)
which(keptVars%in%selectVar(res, comp=1)[[1]]$name)
which(keptVars%in%selectVar(res, comp=2)[[1]]$name)
```

## Networks circos plots


```{r fig.width=8, fig.height=8}
size.variables <- 1
sim <-circosPlot(final.diablo.model, cutoff = 0.5, line = TRUE,
           color.blocks= cols,
           color.cor = c(3,2), size.labels = 1
           , size.variables = size.variables
           , xpd=TRUE)
circosPlot(final.diablo.model, cutoff = 0.75, line = TRUE,
           color.blocks= cols,
           color.cor = c(3,2), size.labels = 1
           , size.variables = size.variables
           , xpd=TRUE)
circosPlot(final.diablo.model, cutoff = 0.9, line = TRUE,
           color.blocks= cols,
           color.cor = c(3,2), size.labels = 1
           , size.variables = size.variables
           , xpd=TRUE)

```

# Networks 

We will prepare partial models for each treatment and treatment combination.

```{r results='asis'}
netlist <- list()
layout.fun <- NULL
for(i in 1:length(.treat)){
thisTreat <-.treat[i]
out037 <- ""
  out037 <- paste( out037, knit_child("037-network.Rmd", 
  quiet=TRUE))
netlist[[thisTreat]] <- RETURN  # complete network

cat(out037)
}
```

```{r}
names(netlist)
```

## Network for `r paste(.treat, collapse=" and ")`.

```{r}
# Complete network, cutoff = 0, all treatments
datasets <- names(CCDATA[-1])
ndatasets<- length(datasets)
#
nname <- paste("../ouptut/figs/network-",paste(useTreatment,collapse=""),sep="")
N12 <- network(res
    , cutoff = 0
    , blocks = 1:ndatasets
    , shape.node = c("rectangle")
    , save = "png"
    , name.save="network-CH"
    )
#
e <- extractEdges2(N12)
colnames(e)[ncol(e)] <- paste(.treat, collapse=".")
head(e)
tail(e)
dim(e)
```

Save networks file for combined and single treatments, stored in `netlist`.
Combine edges from all networks as columns in a data.frame.

```{r}
for (i in 1:length(netlist)) {
e1 <- extractEdges2(netlist[[i]])
colnames(e1)[ncol(e1)] <- names(netlist)[i]
e <- merge(e,e1, sort=FALSE, all=TRUE)
}
```

```{r}
str(e)
```

Compose file name and necessary information for network export file

```{r}
netfn <- paste0("../output/network-",paste(.treat, collapse="_"),"-",paste(datasets, collapse="_"),".txt")
label0 <- paste(paste(.treat, collapse=", "),"|",paste(datasets, collapse=", "),"; cutoff =",0)
title <- label0
sets <- 1:length(DATA)
suffix <- paste0(substr(names(DATA),1,2)[sets[-1]],collapse="-")

```


## Export edges table

```{r  }
#e <- data.frame(x=1:10,y=1:10)
#my.write.table(e, file="network.txt",meta=FALSE)
write.table(e, file = netfn, na="0", sep="\t", col.names=NA, row.names=TRUE)
```

Network edges are exported into file
```{r}
netfn
```

Table with edges for networks based on combined treatments (C, H) and single treatments (C) and (H) is exported as a text file. This table can be used for
inspection and filtering out edges based on selected cutoff.
Missing edges are labeled as weight 0. This enables numeric filtration in other visualization or analysis files (e.g.  Excel).



